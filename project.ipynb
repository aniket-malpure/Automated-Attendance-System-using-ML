{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\hp\\pycharmprojects\\aniket\\dlib-19.19.0-cp37-cp37m-win_amd64.whl\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dlib-19.19.0-cp37-cp37m-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cmake\n",
      "  Downloading cmake-3.18.2.post1-py3-none-win_amd64.whl (34.7 MB)\n",
      "Installing collected packages: cmake\n",
      "Successfully installed cmake-3.18.2.post1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install cmake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting face_recognition\n",
      "  Using cached face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hp\\anaconda3\\lib\\site-packages (from face_recognition) (7.2.0)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from face_recognition) (7.1.2)\n",
      "Requirement already satisfied: dlib>=19.7 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from face_recognition) (19.19.0)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.19.2-cp37-cp37m-win_amd64.whl (12.9 MB)\n",
      "Installing collected packages: numpy, face-recognition\n",
      "Successfully installed face-recognition-1.3.0 numpy-1.19.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "wordcloud 1.7.0 requires matplotlib, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (1.19.2)\n",
      "Collecting as\n",
      "  Downloading as-0.1-py3-none-any.whl (2.2 kB)\n",
      "Collecting np\n",
      "  Downloading np-1.0.2.tar.gz (7.4 kB)\n",
      "Building wheels for collected packages: np\n",
      "  Building wheel for np (setup.py): started\n",
      "  Building wheel for np (setup.py): finished with status 'done'\n",
      "  Created wheel for np: filename=np-1.0.2-py3-none-any.whl size=13656 sha256=99dbb13c96fd7948d600b55c27123537c59c09e7be2f71557b1d4f14af85497a\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\8d\\31\\5b\\f3f27c678f2b3ad7e29903ed09bb7446717fd4c8b35f53973a\n",
      "Successfully built np\n",
      "Installing collected packages: as, np\n",
      "Successfully installed as-0.1 np-1.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.4.0.44-cp37-cp37m-win_amd64.whl (33.5 MB)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from opencv-python) (1.19.2)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.4.0.44\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare all the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_face_encodings = []\n",
    "known_face_names = []\n",
    "known_faces_filenames = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk in the folder to add every file name to known_faces_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (dirpath, dirnames, filenames) in os.walk('ANIKET(F:)/Study/Projects/Data'):\n",
    "    known_faces_filenames.extend(filenames)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walk in the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in known_faces_filenames:\n",
    "    # Load each file\n",
    "    face = face_recognition.load_image_file('ANIKET(F:)/Study/Projects/Data' + filename)\n",
    "    # Extract the name of each employee and add it to known_face_names\n",
    "    known_face_names.append(re.sub(\"[0-9]\",'', filename[:-4]))\n",
    "    # Encode de face of every employee\n",
    "    known_face_encodings.append(face_recognition.face_encodings(face)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Image detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the nameless picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'ANIKET(F:)/Study/Projects/Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9fdc58fc305f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load picture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mface_picture\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_image_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ANIKET(F:)/Study/Projects/Data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Detect faces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mface_locations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_picture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Encore faces\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\face_recognition\\api.py\u001b[0m in \u001b[0;36mload_image_file\u001b[1;34m(file, mode)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mcontents\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \"\"\"\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2877\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2878\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2879\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2880\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'ANIKET(F:)/Study/Projects/Data'"
     ]
    }
   ],
   "source": [
    "\"\"\"# Load picture\n",
    "face_picture = face_recognition.load_image_file(\"ANIKET(F:)/Study/Projects/Data\")\n",
    "# Detect faces\n",
    "face_locations = face_recognition.face_locations(face_picture)\n",
    "# Encore faces\n",
    "face_encodings = face_recognition.face_encodings(face_picture, face_locations)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop in all detected faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for face_encoding in face_encodings:\\n    # See if the face is a match for the known face (that we saved in the precedent step)\\n    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\\n    # name that we will give if the employee is not in the system\\n    name = \"Unknown\"\\n    # check the known face with the smallest distance to the new face\\n    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\\n    # Take the best one\\n    best_match_index = np.argmin(face_distances)\\n    # if we have a match:\\n    if matches[best_match_index]:\\n        # Give the detected face the name of the employee that match\\n        name = known_face_names[best_match_index]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for face_encoding in face_encodings:\n",
    "    # See if the face is a match for the known face (that we saved in the precedent step)\n",
    "    matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "    # name that we will give if the employee is not in the system\n",
    "    name = \"Unknown\"\n",
    "    # check the known face with the smallest distance to the new face\n",
    "    face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "    # Take the best one\n",
    "    best_match_index = np.argmin(face_distances)\n",
    "    # if we have a match:\n",
    "    if matches[best_match_index]:\n",
    "        # Give the detected face the name of the employee that match\n",
    "        name = known_face_names[best_match_index]\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For Video detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the input video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looping through every frame of input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Take every frame\n",
    "    frame = video_capture.read()\n",
    "    # Process every frame only one time\n",
    "    if process_this_frame:\n",
    "        # Find all the faces and face encodings in the current frame of video\n",
    "        face_locations = face_recognition.face_locations(frame)\n",
    "        face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "        # Initialize an array for the name of the detected users\n",
    "        face_names = []\n",
    "        # Initialize JSON to EXPORT\n",
    "        json_to_export = {}\n",
    "        # Loop in every faces detected\n",
    "        for face_encoding in face_encodings:\n",
    "            # See if the face is a match for the known face(s)\n",
    "            matches = face_recognition.compare_faces(known_face_encodings, face_encoding)\n",
    "            name = \"Unknown\"\n",
    "            # check the known face with the smallest distance to the new face\n",
    "            face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "            # Take the best one\n",
    "            best_match_index = np.argmin(face_distances)\n",
    "            # If we have a match\n",
    "            if matches[best_match_index]:\n",
    "                # Save the name of the best match\n",
    "                name = known_face_names[best_match_index]\n",
    "                # SAVE data to send to the API\n",
    "                # Save the time\n",
    "                json_to_export['hour'] = f'{time.localtime().tm_hour}:{time.localtime().tm_min}'\n",
    "                # Save the date\n",
    "                json_to_export['date'] = f'{time.localtime().tm_year}-{time.localtime().tm_mon}-{time.localtime().tm_mday}'\n",
    "                # If you need to save a screenshot:\n",
    "                \"\"\" json_to_export['picture_array'] = frame.tolist() \"\"\"\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
